{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.metrics\n",
    "import sklearn.linear_model\n",
    "import sklearn.preprocessing\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pmdarima as pm\n",
    "import matplotlib.pyplot as plt\n",
    "import bootstrapped.bootstrap as bs\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's be fancy!\n",
    "from IPython.core.display import HTML\n",
    "HTML('<link href=\"https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css\" rel=\"stylesheet\" integrity=\"sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T\" crossorigin=\"anonymous\">')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 class=\"p-3 mb-2 bg-primary text-white\">1. Loading the data set</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv(r\"data/training_dataset.csv\", sep=\";\")\n",
    "Y_train = pd.read_csv(r\"data/training_solution.csv\", sep=\";\", names=X_train.columns)\n",
    "\n",
    "X_test = pd.read_csv(r\"data/test_dataset.csv\", sep=\";\")\n",
    "\n",
    "assert np.array_equal(X_train.columns, X_test.columns)\n",
    "COLS = X_train.columns.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 class=\"p-3 mb-2 bg-primary text-white\">2. Explorative Data Analysis</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 class=\"p-3 mb-2 bg-info text-white\">RQ: How can the data be described?</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.describe()  # train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train.sum(axis=0)  # number of failure labelings per feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.describe()  # test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 class=\"p-3 mb-2 bg-info text-white\">RQ: Is the test data sampled from the same distribution?</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare train and test histograms\n",
    "for col in COLS:\n",
    "    plt.figure(figsize=(25, 5))\n",
    "\n",
    "    # (1) histogram\n",
    "    plt.subplot(1, 2, 1, label=\"histogram\")\n",
    "\n",
    "    bins = np.histogram_bin_edges(np.concatenate([X_train[col], X_test[col]]), bins=50)\n",
    "    plt.hist(X_train[col], alpha=0.5, bins=bins, label=\"train\")\n",
    "    plt.hist(X_test[col], alpha=0.5, bins=bins, label=\"test\")\n",
    "    \n",
    "    plt.legend()\n",
    "    plt.title(\"{} histogram\".format(col))\n",
    "\n",
    "    # (2) raw values\n",
    "    plt.subplot(1, 2, 2, label=\"raw values\")\n",
    "\n",
    "    plt.plot(X_train[col], label=\"train\")        \n",
    "    plt.plot(X_test[col], label=\"test\")\n",
    "\n",
    "    errorband = np.where(Y_train[col])[0]\n",
    "    if len(errorband) > 0:\n",
    "        plt.fill_between(errorband, np.zeros_like(errorband), X_train[col][errorband],\n",
    "                         facecolor='yellow', alpha=0.5, label=\"failures\")\n",
    "\n",
    "    plt.legend()\n",
    "    plt.title(\"{} raw values\".format(col))\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 class=\"p-3 mb-2 bg-info text-white\">RQ: Are the features correlated?</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_features(x, y=None, name=\"\"):\n",
    "    plt.figure(figsize=(20, 1.1 * x.shape[1]))\n",
    "    for i, col in enumerate(x.columns):\n",
    "        y_ = sklearn.preprocessing.minmax_scale(x[col]) + i + 0.5\n",
    "        plt.plot(y_, label=col)\n",
    "\n",
    "        if y is not None:\n",
    "            errorband = np.where(y[col])[0]\n",
    "            if len(errorband) > 0:\n",
    "                plt.fill_between(errorband, np.full_like(errorband, i + 0.5, dtype=np.float),\n",
    "                                 y_[errorband], facecolor='yellow', alpha=0.75)\n",
    "        \n",
    "    plt.gca().set_yticks(np.arange(1, len(x.columns) + 1))\n",
    "    plt.gca().set_xticks(np.arange(len(x), step=20))\n",
    "    plt.gca().set_axisbelow(True)\n",
    "    plt.grid(axis=\"x\")\n",
    "    plt.legend()\n",
    "    plt.title(\"feature correlation {}\".format(name))\n",
    "    plt.show()\n",
    "    \n",
    "visualize_features(X_train, Y_train, name=\"train\")\n",
    "visualize_features(X_test, name=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_correlation_coefficients(x, name=\"\", method=\"spearman\"):\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    im = plt.imshow(np.abs(x.corr(method)), cmap=\"viridis\")\n",
    "    \n",
    "    ticks = np.arange(0, len(x.columns))\n",
    "    labels = ticks + 1\n",
    "    plt.gca().set_xticks(ticks)\n",
    "    plt.gca().set_yticks(ticks)\n",
    "    plt.gca().set_xticklabels(labels)\n",
    "    plt.gca().set_yticklabels(labels)\n",
    "    \n",
    "    plt.title(\"absolute feature correlation {}\".format(name))\n",
    "    plt.colorbar(im)\n",
    "    plt.show()\n",
    "    \n",
    "visualize_correlation_coefficients(X_train, \"train\")\n",
    "visualize_correlation_coefficients(X_test, \"test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 class=\"p-3 mb-2 bg-primary text-white\">3. Data Preprocessing</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 class=\"p-3 mb-2 bg-info text-white\">Fix the erros in the training data set</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_features_heuristically(x, y):\n",
    "    # fix constant offset in x2 by subtracting the mean\n",
    "    y2_errorband = np.where(y[\"x2\"])[0]\n",
    "    y2_faulty = x[\"x2\"][y2_errorband].values\n",
    "    x2_faulty = np.arange(len(y2_faulty)).reshape(-1, 1)\n",
    "    \n",
    "    y2_offset = np.mean(y2_faulty) - np.median(x[\"x2\"])\n",
    "    \n",
    "    y2_fixed = y2_faulty - y2_offset\n",
    "    \n",
    "    # fix constant trend in x3 by subtracting the linear component\n",
    "    y3_errorband = np.where(y[\"x3\"])[0]\n",
    "    y3_faulty = x[\"x3\"][y3_errorband].values\n",
    "    x3_faulty = np.arange(len(y3_faulty)).reshape(-1, 1)\n",
    "    \n",
    "    linreg = sklearn.linear_model.LinearRegression()\n",
    "    model = linreg.fit(x3_faulty, y3_faulty)\n",
    "    \n",
    "    y3_fixed = y3_faulty - (x3_faulty * model.coef_).ravel()\n",
    "    \n",
    "    # build the new data frame\n",
    "    result = x.copy()\n",
    "    result.loc[y2_errorband, \"x2\"] = y2_fixed\n",
    "    result.loc[y3_errorband, \"x3\"] = y3_fixed\n",
    "    \n",
    "    return result\n",
    "\n",
    "X_train_fixed = fix_features_heuristically(X_train, Y_train)\n",
    "\n",
    "visualize_features(pd.DataFrame(X_train.loc[:, [\"x2\", \"x3\"]]), Y_train, name=\"train (original x2 + x3)\")\n",
    "visualize_features(pd.DataFrame(X_train_fixed.loc[:, [\"x2\", \"x3\"]]), Y_train, name=\"train (fixed x2 + x3)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 class=\"p-3 mb-2 bg-info text-white\">Correlation Confidence Intervals</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correlation_confidence_interval(a, b, alpha=0.05, method=\"spearman\"):\n",
    "    # (c) http://onlinestatbook.com/2/estimation/correlation_ci.html\n",
    "    assert method == \"pearson\" or method == \"spearman\"\n",
    "    \n",
    "    n = len(a)\n",
    "    r, p = scipy.stats.pearsonr(a, b) if method == \"pearson\" else scipy.stats.spearmanr(a, b)\n",
    "    z_ = np.arctanh(r)  # transform r to fisher z score\n",
    "    \n",
    "    stderr = 1.0 / math.sqrt(n - 3)  # standard error or normally-distributed sampling distribution\n",
    "    z_crit = scipy.stats.norm.ppf(1 - alpha / 2)  # 2-tailed z critical value\n",
    "\n",
    "    r_low = np.tanh(z_ - z_crit * stderr)\n",
    "    r_high = np.tanh(z_ + z_crit * stderr)\n",
    "    \n",
    "    return r_low, r_high"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 class=\"p-3 mb-2 bg-primary text-white\">4. Predictive Models</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_prediction(x_true, x_pred, x_pred_offset=0, name=\"\",\n",
    "                         error_inner=None, error_outer=None, error_lower=None, error_upper=None):\n",
    "    plt.figure(figsize=(20, 4))\n",
    "    \n",
    "    x_true_range = np.arange(len(x_true))\n",
    "    x_pred_range = np.arange(x_pred_offset, len(x_pred) + x_pred_offset)\n",
    "               \n",
    "    plt.plot(x_true_range, x_true, color=\"black\", alpha=0.5, ls=\"--\", label=\"true\")\n",
    "    plt.plot(x_pred_range, x_pred, color=\"orange\", label=\"prediction\")\n",
    "    \n",
    "    assert (error_inner is not None or error_outer is not None) ^ (error_lower is not None or error_upper is not None)\n",
    "    \n",
    "    if error_inner is not None:\n",
    "        plt.fill_between(x_pred_range, x_pred - error_inner, x_pred + error_inner, color=\"orange\", alpha=0.2)\n",
    "    if error_outer is not None:\n",
    "        plt.fill_between(x_pred_range, x_pred - error_outer, x_pred + error_outer, color=\"orange\", alpha=0.2)\n",
    "    if error_lower is not None or error_upper is not None:\n",
    "        error_lower = error_lower if error_lower is not None else np.zeros_like(x_pred)\n",
    "        error_upper = error_upper if error_upper is not None else np.zeros_like(x_pred)\n",
    "        plt.fill_between(x_pred_range, x_pred - error_lower, x_pred + error_upper, color=\"orange\", alpha=0.2)\n",
    "    \n",
    "    plt.title(\"feature predictions {}\".format(name))\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 class=\"p-3 mb-2 bg-info text-white\">Ridge Regression</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ridge_regression(train, column, test=None, test_names=None, ridge_alpha=100, ci_alpha=0.01):\n",
    "    test = test if test is not None else train\n",
    "    test_names = test_names if test_names is not None else \"\"\n",
    "    if not isinstance(test, (list,)):\n",
    "        test = [test]\n",
    "    if not isinstance(test_names, (list,)):\n",
    "        test_names = [test_names]\n",
    "        \n",
    "    X, y = train.loc[:, COLS != column], train[column]\n",
    "    Z = np.column_stack([X, y])\n",
    "    \n",
    "    ridge = sklearn.linear_model.Ridge(alpha=ridge_alpha)\n",
    "    scaler = sklearn.preprocessing.MinMaxScaler().fit(X, y)\n",
    "    model = ridge.fit(scaler.transform(X), y)\n",
    "    \n",
    "    def _ridge_predict_error(values):\n",
    "        X_, y_true = values[:, :-1], values[:, -1]\n",
    "        y_pred = model.predict(scaler.transform(X_))\n",
    "        return np.percentile(np.abs(y_true - y_pred), q=95)\n",
    "    \n",
    "    def _ridge_predict_error_bootstrap(samples):\n",
    "        if samples.ndim == 2:  # single observation\n",
    "            return [_ridge_predict_error(samples)]\n",
    "        return [_ridge_predict_error(samples[i, :, :]) for i in range(samples.shape[0])]\n",
    "    \n",
    "    # do bootstrap to get confidence interval\n",
    "    ci = bs.bootstrap(Z, stat_func=_ridge_predict_error_bootstrap, alpha=ci_alpha)\n",
    "    \n",
    "    # prediction\n",
    "    for t, n in zip(test, test_names):\n",
    "        X_, y_ = t.loc[:, COLS != column], t[column]\n",
    "        \n",
    "        prediction = model.predict(scaler.transform(X_))\n",
    "        visualize_prediction(y_, prediction, error_outer=ci.upper_bound, name=\"{} {}\".format(n, column))\n",
    "\n",
    "for col in COLS:\n",
    "    ridge_regression(X_train_fixed, col, test=[X_train, X_test], test_names=[\"train\", \"test\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 class=\"p-3 mb-2 bg-info text-white\">ARMAX Forecasting</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def autoarima(train, column, test=None, test_offset=0.1):\n",
    "    test = test if test is not None else train\n",
    "    if not isinstance(test, (list,)):\n",
    "        test = [test]\n",
    "        \n",
    "    X, y = train.loc[:, COLS != column], train[column]\n",
    "    Z = np.column_stack([X, y])\n",
    "    \n",
    "    model = pm.auto_arima(y=y, exogenous=X, seasonal=False,\n",
    "                          error_action='ignore', suppress_warnings=True, stepwise=True)\n",
    "    # display(model.summary())\n",
    "    \n",
    "    # prediction\n",
    "    for t in test:\n",
    "        test_offset_len = int(len(t) * test_offset)\n",
    "        X_, y_ = t.loc[:, COLS != column], t[column]\n",
    "        \n",
    "        model.update(y_[:test_offset_len], exogenous=X_[:test_offset_len])\n",
    "        prediction, errorband = model.predict(exogenous=X_, n_periods=len(t), return_conf_int=True)\n",
    "        \n",
    "        visualize_prediction(t[column], prediction, error_lower=prediction - errorband[:, 0], error_upper=errorband[:, 1] - prediction, x_pred_offset=0, name=column)\n",
    "    \n",
    "for col in COLS:\n",
    "    autoarima(X_train_fixed, col, test=[X_train, X_test])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
